{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, we will evaluate the responses generated by the LLMs.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question.text</th>\n",
       "      <th>own_opinion.text</th>\n",
       "      <th>question_topic</th>\n",
       "      <th>question_id</th>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <th>gpt-4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are laws banning private education a good idea?</td>\n",
       "      <td>[I am indifferent regarding this statement for...</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>The debate over whether laws banning private e...</td>\n",
       "      <td>Banning private education completely may not b...</td>\n",
       "      <td>The question of whether laws banning private e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If we could extend human life by 50 years, sho...</td>\n",
       "      <td>[I think we should always advance science and ...</td>\n",
       "      <td>90</td>\n",
       "      <td>128</td>\n",
       "      <td>The question of whether we should extend human...</td>\n",
       "      <td>This question is highly subjective and there a...</td>\n",
       "      <td>Extending human life by 50 years is a complex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it OK to use animal products at all for bea...</td>\n",
       "      <td>[I do not think it is ok to use animal product...</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>The use of animal products in beauty care is a...</td>\n",
       "      <td>This is a personal choice and ultimately depen...</td>\n",
       "      <td>The use of animal products in beauty care is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the use of fossil fuels doing more harm tha...</td>\n",
       "      <td>[This question is if you believe in man- made ...</td>\n",
       "      <td>39</td>\n",
       "      <td>343</td>\n",
       "      <td>The impact of fossil fuels on the economy is a...</td>\n",
       "      <td>The use of fossil fuels has both positive and ...</td>\n",
       "      <td>The use of fossil fuels is a complex issue wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Should parents have a legal right to override ...</td>\n",
       "      <td>[Parents should have a legal right to some deg...</td>\n",
       "      <td>61</td>\n",
       "      <td>511</td>\n",
       "      <td>The question of whether parents should have a ...</td>\n",
       "      <td>There is no simple answer to this question as ...</td>\n",
       "      <td>The question of whether parents should have a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question.text  \\\n",
       "0    Are laws banning private education a good idea?   \n",
       "1  If we could extend human life by 50 years, sho...   \n",
       "2  Is it OK to use animal products at all for bea...   \n",
       "3  Is the use of fossil fuels doing more harm tha...   \n",
       "4  Should parents have a legal right to override ...   \n",
       "\n",
       "                                    own_opinion.text  question_topic  \\\n",
       "0  [I am indifferent regarding this statement for...              70   \n",
       "1  [I think we should always advance science and ...              90   \n",
       "2  [I do not think it is ok to use animal product...               5   \n",
       "3  [This question is if you believe in man- made ...              39   \n",
       "4  [Parents should have a legal right to some deg...              61   \n",
       "\n",
       "   question_id                                        gpt-4o-mini  \\\n",
       "0            7  The debate over whether laws banning private e...   \n",
       "1          128  The question of whether we should extend human...   \n",
       "2          157  The use of animal products in beauty care is a...   \n",
       "3          343  The impact of fossil fuels on the economy is a...   \n",
       "4          511  The question of whether parents should have a ...   \n",
       "\n",
       "                                       gpt-3.5-turbo  \\\n",
       "0  Banning private education completely may not b...   \n",
       "1  This question is highly subjective and there a...   \n",
       "2  This is a personal choice and ultimately depen...   \n",
       "3  The use of fossil fuels has both positive and ...   \n",
       "4  There is no simple answer to this question as ...   \n",
       "\n",
       "                                              gpt-4o  \n",
       "0  The question of whether laws banning private e...  \n",
       "1  Extending human life by 50 years is a complex ...  \n",
       "2  The use of animal products in beauty care is a...  \n",
       "3  The use of fossil fuels is a complex issue wit...  \n",
       "4  The question of whether parents should have a ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('data/habermas_machine_questions_with_responses.csv')\n",
    "df_questions['own_opinion.text'] = df_questions['own_opinion.text'].apply(ast.literal_eval)\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to see if the opinions are all represented in the generated responses.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def is_my_opinion_represented(question, response, opinion):\n",
    "    \"\"\"\n",
    "    Determine if the following opinion is represented in the response to a question. This is the simplest approach I can think of.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Task: Determine if the following opinion is represented in the response to a question.\n",
    "\n",
    "Question: {question}\n",
    "Response: {response}\n",
    "Opinion to check for: {opinion}\n",
    "\n",
    "Instructions:\n",
    "- Answer ONLY with 'yes' or 'no'\n",
    "- Answer 'yes' if the opinion is clearly represented\n",
    "- Answer 'no' if the opinion is absent\n",
    "- Do not explain your reasoning\n",
    "- Do not add any other text\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise evaluator that only responds with 'yes' or 'no'.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,  # Use 0 for maximum consistency\n",
    "        max_tokens=1, # We only need one token for 'yes' or 'no'\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_my_opinion_represented_with_cot_michiel(question, response, opinion):\n",
    "    \"\"\"\n",
    "    Determine if the following opinion is represented in the response to a question. Using a CoT with XML formatting (task for Michiel Bakker).\n",
    "    \"\"\"\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ThinkingStep(BaseModel):\n",
    "    step_number: int\n",
    "    thought: str\n",
    "\n",
    "class RepresentationChain(BaseModel):\n",
    "    steps: list[ThinkingStep]\n",
    "    relevance_score: int\n",
    "\n",
    "def is_my_opinion_represented_structured_cot(question, response, opinion):\n",
    "    \"\"\"\n",
    "    Determine if the opinion is represented in the response to a question, using structured CoT generation.\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"Task: Determine if the opinion is represented in the response to the question. \n",
    "You should think step-by-step about the question and response to determine if the opinion is represented and then give a score between 0 and 10 of how well it is represented.\n",
    "\"\"\"\n",
    "    \n",
    "    prompt =\"\"\"Question: {question}\n",
    "Response: {response}\n",
    "Opinion to check for: {opinion}\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a precise evaluator that only responds with 'yes' or 'no'.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,  # Use 0 for maximum consistency\n",
    "        response_format={\n",
    "            'type': 'json_schema',\n",
    "            'json_schema': \n",
    "                {\n",
    "                \"name\": \"RepresentationChain\", \n",
    "                \"schema\": RepresentationChain.model_json_schema()\n",
    "                }\n",
    "            } \n",
    "    )\n",
    "    \n",
    "    result_object = json.loads(completion.choices[0].message.content)\n",
    "    return result_object\n",
    "\n",
    "def process_representation_result(result_object):\n",
    "    return result_object['relevance_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ThinkingStep(BaseModel):\n",
    "    step_number: int\n",
    "    thought: str\n",
    "\n",
    "class EntailmentJSON(BaseModel):\n",
    "    matches: list[str]\n",
    "\n",
    "class EntailmentChain(BaseModel):\n",
    "    steps: list[ThinkingStep]\n",
    "    final_answer: EntailmentJSON\n",
    "\n",
    "def entailment_from_gpt_json(question: str, response: str, opinion: str):\n",
    "    \"\"\"\n",
    "    Find exact text matches between rich text and opinion using GPT-4.\n",
    "\n",
    "    Args:\n",
    "        question: Context question or query\n",
    "        response: Source text to find matches in\n",
    "        opinion: Opinion text to match against\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing matches as an array of strings\n",
    "    \"\"\"\n",
    "    system_prompt = f\"\"\"Task: Text Entailment. Find the exact words in the Rich Text question response that specifically represent the content expressed in the Opinion.\n",
    "\n",
    "Instructions:\n",
    "1. For each concept in the Opinion, find the sentences in the Rich Text that specifically represent the content expressed in the Opinion. Think through this step-by-step.\n",
    "2. Return the EXACT text from the Rich Text that represents the content expressed in the Opinion.\n",
    "\n",
    "Important:\n",
    "- Do not paraphrase or interpret - use the exact text.\n",
    "- Each match must be a continuous span of text.\n",
    "\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"Context question: {question}\n",
    "Rich Text: {response}\n",
    "Opinion: {opinion}\n",
    "\n",
    "Find the text that is entailed by the opinion.\"\"\"\n",
    "\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0,  # Use 0 for maximum consistency\n",
    "        response_format={\n",
    "            'type': 'json_schema',\n",
    "            'json_schema': \n",
    "                {\n",
    "                \"name\": \"EntailmentChain\", \n",
    "                \"schema\": EntailmentChain.model_json_schema()\n",
    "                }\n",
    "            } \n",
    "    )\n",
    "\n",
    "    result_object = json.loads(chat_response.choices[0].message.content)\n",
    "    return result_object\n",
    "\n",
    "def process_entailment_result(result_object, response):\n",
    "    matches = []\n",
    "    for match in result_object['final_answer']['matches']:\n",
    "        start_index = response.lower().find(match.lower())\n",
    "        end_index = start_index + len(match)\n",
    "        matches.append((start_index, end_index))\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-4o-mini', 'gpt-3.5-turbo','gpt-4o']\n",
    "\n",
    "overton_results = []\n",
    "for _, row in tqdm(df_questions.iterrows(), total=df_questions.shape[0]):\n",
    "    question = row['question.text']\n",
    "    opinions = row['own_opinion.text']\n",
    "    question_id = row['question_id']\n",
    "    for opinion_idx, opinion in enumerate(opinions):\n",
    "        for model in models:\n",
    "            response = row[model]\n",
    "            result_opinion_represented = is_my_opinion_represented(question, response, opinion)\n",
    "            result_structured_cot = is_my_opinion_represented_structured_cot(question, response, opinion)\n",
    "            entailment_result = entailment_from_gpt_json(question, response, opinion)\n",
    "            entailment_matches = process_entailment_result(entailment_result, response)\n",
    "\n",
    "            overton_results.append({\n",
    "                'question_id': question_id,\n",
    "                'opinion_idx': opinion_idx,\n",
    "                'model': model,\n",
    "                'is_represented_simple_prompt': result_opinion_represented == 'yes',\n",
    "                'is_represented_structured_cot': result_structured_cot,\n",
    "                'is_represented_structured_cot_score': process_representation_result(result_structured_cot),\n",
    "                'entailment_result': entailment_result,\n",
    "                'entailment_matches': entailment_matches\n",
    "            })\n",
    "\n",
    "df_overton_results = pd.DataFrame(overton_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>opinion_idx</th>\n",
       "      <th>model</th>\n",
       "      <th>is_represented_simple_prompt</th>\n",
       "      <th>is_represented_structured_cot</th>\n",
       "      <th>is_represented_structured_cot_score</th>\n",
       "      <th>entailment_result</th>\n",
       "      <th>entailment_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 75)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(1424, 1545), (1926, 2071), (1676, 1819)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 99), (104, 186)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(1155, 1301), (253, 390), (1343, 1469)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 225), (-1, 255)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 187)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 162), (1343, 1469), (1581, 1660)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 225), (-1, 255)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 99), (197, 318)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(1155, 1301), (1706, 1865)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(269, 351), (920, 1062), (1941, 2070)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(121, 186)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(253, 390)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(620, 655), (1200, 1224), (1388, 1404)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(247, 281), (421, 592)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(1596, 1763), (693, 853), (577, 640)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 99), (-1, 178), (1989, 2192)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 186), (421, 593)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 131), (468, 640), (1965, 2236)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 168)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(286, 400)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(1855, 1947)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 178), (-1, 177)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(421, 592)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>True</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>8</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(468, 640), (693, 853), (883, 990)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(-1, 178), (-1, 186), (-1, 177)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(421, 592)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(468, 640), (1596, 1763), (1199, 1314)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(169, 357), (802, 926)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(0, 87), (88, 218), (219, 362), (363, 450)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(219, 343), (1502, 1644)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(169, 357), (484, 567), (1293, 1375)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>False</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'Iden...</td>\n",
       "      <td>7</td>\n",
       "      <td>{'steps': [{'step_number': 1, 'thought': 'The ...</td>\n",
       "      <td>[(88, 218), (219, 362), (363, 450)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id  opinion_idx          model  is_represented_simple_prompt  \\\n",
       "0             7            0    gpt-4o-mini                         False   \n",
       "1             7            0  gpt-3.5-turbo                         False   \n",
       "2             7            0         gpt-4o                         False   \n",
       "3             7            1    gpt-4o-mini                          True   \n",
       "4             7            1  gpt-3.5-turbo                         False   \n",
       "5             7            1         gpt-4o                          True   \n",
       "6             7            2    gpt-4o-mini                          True   \n",
       "7             7            2  gpt-3.5-turbo                         False   \n",
       "8             7            2         gpt-4o                         False   \n",
       "9             7            3    gpt-4o-mini                         False   \n",
       "10            7            3  gpt-3.5-turbo                         False   \n",
       "11            7            3         gpt-4o                         False   \n",
       "12            7            4    gpt-4o-mini                         False   \n",
       "13            7            4  gpt-3.5-turbo                         False   \n",
       "14            7            4         gpt-4o                         False   \n",
       "15          128            0    gpt-4o-mini                         False   \n",
       "16          128            0  gpt-3.5-turbo                         False   \n",
       "17          128            0         gpt-4o                         False   \n",
       "18          128            1    gpt-4o-mini                          True   \n",
       "19          128            1  gpt-3.5-turbo                          True   \n",
       "20          128            1         gpt-4o                          True   \n",
       "21          128            2    gpt-4o-mini                         False   \n",
       "22          128            2  gpt-3.5-turbo                         False   \n",
       "23          128            2         gpt-4o                         False   \n",
       "24          128            3    gpt-4o-mini                          True   \n",
       "25          128            3  gpt-3.5-turbo                         False   \n",
       "26          128            3         gpt-4o                          True   \n",
       "27          128            4    gpt-4o-mini                         False   \n",
       "28          128            4  gpt-3.5-turbo                         False   \n",
       "29          128            4         gpt-4o                         False   \n",
       "30          157            0    gpt-4o-mini                         False   \n",
       "31          157            0  gpt-3.5-turbo                         False   \n",
       "32          157            0         gpt-4o                         False   \n",
       "33          157            1    gpt-4o-mini                         False   \n",
       "34          157            1  gpt-3.5-turbo                         False   \n",
       "\n",
       "                        is_represented_structured_cot  \\\n",
       "0   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "1   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "2   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "3   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "4   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "5   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "6   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "7   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "8   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "9   {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "10  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "11  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "12  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "13  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "14  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "15  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "16  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "17  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "18  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "19  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "20  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "21  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "22  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "23  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "24  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "25  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "26  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "27  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "28  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "29  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "30  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "31  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "32  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "33  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "34  {'steps': [{'step_number': 1, 'thought': 'Iden...   \n",
       "\n",
       "    is_represented_structured_cot_score  \\\n",
       "0                                     7   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     7   \n",
       "4                                     8   \n",
       "5                                     7   \n",
       "6                                     8   \n",
       "7                                     7   \n",
       "8                                     0   \n",
       "9                                     0   \n",
       "10                                    0   \n",
       "11                                    0   \n",
       "12                                    0   \n",
       "13                                    8   \n",
       "14                                    0   \n",
       "15                                    0   \n",
       "16                                    0   \n",
       "17                                    7   \n",
       "18                                    0   \n",
       "19                                    0   \n",
       "20                                    8   \n",
       "21                                    0   \n",
       "22                                    0   \n",
       "23                                    7   \n",
       "24                                    7   \n",
       "25                                    0   \n",
       "26                                    8   \n",
       "27                                    0   \n",
       "28                                    0   \n",
       "29                                    7   \n",
       "30                                    0   \n",
       "31                                    0   \n",
       "32                                    0   \n",
       "33                                    0   \n",
       "34                                    7   \n",
       "\n",
       "                                    entailment_result  \\\n",
       "0   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "1   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "2   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "3   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "4   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "5   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "6   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "7   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "8   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "9   {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "10  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "11  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "12  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "13  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "14  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "15  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "16  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "17  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "18  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "19  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "20  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "21  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "22  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "23  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "24  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "25  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "26  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "27  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "28  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "29  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "30  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "31  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "32  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "33  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "34  {'steps': [{'step_number': 1, 'thought': 'The ...   \n",
       "\n",
       "                              entailment_matches  \n",
       "0                                             []  \n",
       "1                                      [(0, 75)]  \n",
       "2                                             []  \n",
       "3     [(1424, 1545), (1926, 2071), (1676, 1819)]  \n",
       "4                          [(0, 99), (104, 186)]  \n",
       "5       [(1155, 1301), (253, 390), (1343, 1469)]  \n",
       "6                         [(-1, 225), (-1, 255)]  \n",
       "7                                     [(0, 187)]  \n",
       "8        [(-1, 162), (1343, 1469), (1581, 1660)]  \n",
       "9                         [(-1, 225), (-1, 255)]  \n",
       "10                         [(0, 99), (197, 318)]  \n",
       "11                  [(1155, 1301), (1706, 1865)]  \n",
       "12       [(269, 351), (920, 1062), (1941, 2070)]  \n",
       "13                                  [(121, 186)]  \n",
       "14                                  [(253, 390)]  \n",
       "15      [(620, 655), (1200, 1224), (1388, 1404)]  \n",
       "16                      [(247, 281), (421, 592)]  \n",
       "17        [(1596, 1763), (693, 853), (577, 640)]  \n",
       "18            [(0, 99), (-1, 178), (1989, 2192)]  \n",
       "19                        [(0, 186), (421, 593)]  \n",
       "20          [(0, 131), (468, 640), (1965, 2236)]  \n",
       "21                                   [(-1, 168)]  \n",
       "22                                  [(286, 400)]  \n",
       "23                                [(1855, 1947)]  \n",
       "24                        [(-1, 178), (-1, 177)]  \n",
       "25                                  [(421, 592)]  \n",
       "26          [(468, 640), (693, 853), (883, 990)]  \n",
       "27             [(-1, 178), (-1, 186), (-1, 177)]  \n",
       "28                                  [(421, 592)]  \n",
       "29      [(468, 640), (1596, 1763), (1199, 1314)]  \n",
       "30                      [(169, 357), (802, 926)]  \n",
       "31  [(0, 87), (88, 218), (219, 362), (363, 450)]  \n",
       "32                    [(219, 343), (1502, 1644)]  \n",
       "33        [(169, 357), (484, 567), (1293, 1375)]  \n",
       "34           [(88, 218), (219, 362), (363, 450)]  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overton_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overton_results = pd.DataFrame(overton_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overton_results['represented_bool'] = df_overton_results['represented'] == 'yes'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>represented_bool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>619.4</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o</th>\n",
       "      <td>619.4</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini</th>\n",
       "      <td>619.4</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               question_id  represented_bool\n",
       "model                                       \n",
       "gpt-3.5-turbo        619.4             0.245\n",
       "gpt-4o               619.4             0.325\n",
       "gpt-4o-mini          619.4             0.350"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overton_results.groupby(['model', 'question_id'])['represented_bool'].mean().reset_index().groupby('model').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
